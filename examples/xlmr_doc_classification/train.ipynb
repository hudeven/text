{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!git clone https://github.com/hudeven/text\n",
    "!git clone https://github.com/facebookresearch/pytext\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade --force-reinstall ./text/stl_text/dataframes/datasets;\n",
    "!pip install --upgrade --force-reinstall ./text;\n",
    "\n",
    "!pip install --upgrade --force-reinstall ./pytext;\n",
    "!pip install --upgrade --force-reinstall tensorboard;\n",
    "\n",
    "!pip install --upgrade --force-reinstall --pre torch torchtext -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html;\n",
    "!pip install --upgrade --force-reinstall datasets;\n",
    "\n",
    "!pip install pytorch-lightning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run failed to load cuda module:No module named 'caffe2.python.caffe2_pybind11_state_gpu',and AMD hip module:No module named 'caffe2.python.caffe2_pybind11_state_hip'.Will run in CPU only mode.\n",
      "Install apex from https://github.com/NVIDIA/apex/.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from stl_text.ops.utils.arrow import convert_csv_to_arrow\n",
    "from stl_text.datamodule import DocClassificationDataModule\n",
    "from task import XlmrDocClassificationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenliu/opt/anaconda3/envs/fun/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "WARNING:stl_text.ops.utils.arrow:converted to arrow and saved to ./glue_sst2_tiny/train\n",
      "WARNING:stl_text.ops.utils.arrow:converted to arrow and saved to ./glue_sst2_tiny/valid\n",
      "WARNING:stl_text.ops.utils.arrow:converted to arrow and saved to ./glue_sst2_tiny/test\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-db49ecf2f701544f.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-dcde595fba10e695.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-f079b8abbf5c8c2d.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-3d000a9a67cbc194.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-d2d1ee7a6ae2efaf.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-b09e70b8b24063db.arrow\n",
      "GPU available: False, used: False\n",
      "INFO:lightning:GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "INFO:lightning:Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "/Users/stevenliu/workspace/lightning/metric_fix/pytorch-lightning/pytorch_lightning/utilities/distributed.py:45: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name           | Type                | Params\n",
      "-------------------------------------------------------\n",
      "0 | text_transform | WhitespaceTokenizer | 0     \n",
      "1 | loss           | CrossEntropyLoss    | 0     \n",
      "2 | valid_acc      | Accuracy            | 0     \n",
      "3 | test_acc       | Accuracy            | 0     \n",
      "4 | model          | RobertaModel        | 124 M \n",
      "INFO:lightning:\n",
      "  | Name           | Type                | Params\n",
      "-------------------------------------------------------\n",
      "0 | text_transform | WhitespaceTokenizer | 0     \n",
      "1 | loss           | CrossEntropyLoss    | 0     \n",
      "2 | valid_acc      | Accuracy            | 0     \n",
      "3 | test_acc       | Accuracy            | 0     \n",
      "4 | model          | RobertaModel        | 124 M \n",
      "/Users/stevenliu/workspace/lightning/metric_fix/pytorch-lightning/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/stevenliu/opt/anaconda3/envs/fun/lib/python3.7/site-packages/pytext/models/representations/transformer/multihead_attention.py:58: UserWarning: Output 0 of SplitBackward is a view and is being modified inplace. This view is an output of a function that returns multiple views. Inplace operators on such views are being deprecated and will be forbidden starting from version 1.8. Consider using `unsafe_` version of the function that produced this view or don't modify this view inplace. (Triggered internally at  ../torch/csrc/autograd/variable.cpp:483.)\n",
      "  q *= self.scaling\n",
      "/Users/stevenliu/opt/anaconda3/envs/fun/lib/python3.7/site-packages/torch/serialization.py:589: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  \" silence this warning)\", UserWarning)\n",
      "/Users/stevenliu/opt/anaconda3/envs/fun/lib/python3.7/site-packages/torch/nn/modules/module.py:744: UserWarning: Output 0 of SplitBackward is a view and is being modified inplace. This view is an output of a function that returns multiple views. Inplace operators on such views are being deprecated and will be forbidden starting from version 1.8. Consider using `unsafe_` version of the function that produced this view or don't modify this view inplace. (Triggered internally at  ../torch/csrc/autograd/variable.cpp:483.)\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "705bdf73006d4758a22aa58d446ef080"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[-0.9838,  0.7541],\n",
      "        [-0.9837,  0.7540]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# convert csv to arrow format (only required for the first time)\n",
    "data_path = \"./glue_sst2_tiny\"\n",
    "for split in (\"train.tsv\", \"valid.tsv\", \"test.tsv\"):\n",
    "    split_path = os.path.join(data_path, split)\n",
    "    convert_csv_to_arrow(split_path)\n",
    "\n",
    "# setup datamodule\n",
    "datamodule = DocClassificationDataModule(data_path=data_path, batch_size=8)\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "# construct task\n",
    "task = XlmrDocClassificationTask(text_transform=datamodule.text_transform, num_class=2,\n",
    "                                 lr=0.01)\n",
    "\n",
    "# train model\n",
    "trainer = Trainer(max_epochs=5, fast_dev_run=True)\n",
    "trainer.fit(task, datamodule=datamodule)\n",
    "\n",
    "# export to TorchScript\n",
    "export_path = \"/tmp/doc_task.pt1\"\n",
    "task.to_torchscript(\"/tmp/doc_task.pt1\")\n",
    "with open(export_path, \"rb\") as f:\n",
    "    ts_module = torch.load(f)\n",
    "    print(ts_module(text_batch=[\"hello world\", \"attend is all your need!\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}