{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/hudeven/text\n",
    "!pip install --upgrade -e ./text;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from pytorch_lightning import Trainer\n",
    "from stl_text.ops.utils.arrow import convert_csv_to_arrow\n",
    "from stl_text.datamodule import DocClassificationDataModule\n",
    "from stl_text.models import RobertaModel\n",
    "from task import DocClassificationTask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converted to arrow and saved to ./glue_sst2_tiny/train\n",
      "converted to arrow and saved to ./glue_sst2_tiny/valid\n",
      "converted to arrow and saved to ./glue_sst2_tiny/test\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-f1e83dde37d3c060.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-e464112f4fa64676.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-3301217692ea7b7c.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-d7e81757a0546a02.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-daf7dc6f6a37bdc1.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-a1235ce082fa5b2a.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-4a8ddec11e8e0938.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-a6e5e3e4a7b8c81f.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-c33ac2d9284c0aa3.arrow\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es)\n",
      "/Users/stevenliu/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name           | Type                | Params\n",
      "-------------------------------------------------------\n",
      "0 | text_transform | WhitespaceTokenizer | 0     \n",
      "1 | model          | RobertaModel        | 13.5 M\n",
      "2 | loss           | CrossEntropyLoss    | 0     \n",
      "3 | valid_acc      | Accuracy            | 0     \n",
      "4 | test_acc       | Accuracy            | 0     \n",
      "-------------------------------------------------------\n",
      "13.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.5 M    Total params\n",
      "/Users/stevenliu/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/stevenliu/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/stevenliu/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/torch/serialization.py:589: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  \" silence this warning)\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e92195f4cb1b4c56bb03cbc981145289"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.5000), 'test_loss': tensor(9.0768)}\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([[-9.4245,  8.7131],\n",
      "        [-9.6996,  9.0748]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72c1a06d75bd49f8b05ac215d3101e22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e41869b242b44f37a93d776cadd74e34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79b0e98858954c1cbbd2b28ed934ffd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0eff6f3c7e4647409140a2ffcc4cb07e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5046bcaf5e57450ab0f961aa44eda549"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caaf87f5ee8e4d119bec250869ec0127"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a7a5ed15ba64b89b064505b6eeb0720"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ca805b8fc604a3683c8e3610d0dbb1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7966b5f4902247adad3249f6ca4003e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0105566fd47f407eb8e12b0adec7dcdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert csv to arrow format (only required for the first time)\n",
    "data_path = \"./glue_sst2_tiny\"\n",
    "for split in (\"train.tsv\", \"valid.tsv\", \"test.tsv\"):\n",
    "    split_path = os.path.join(data_path, split)\n",
    "    convert_csv_to_arrow(split_path)\n",
    "\n",
    "# setup datamodule\n",
    "datamodule = DocClassificationDataModule(data_path=data_path, batch_size=8, drop_last=True)\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "# build task\n",
    "model = RobertaModel(\n",
    "    vocab_size=1000,\n",
    "    embedding_dim=1000,\n",
    "    num_attention_heads=1,\n",
    "    num_encoder_layers=1,\n",
    "    output_dropout=0.4,\n",
    "    out_dim=2,\n",
    ")\n",
    "optimizer = AdamW(model.parameters(), lr=0.01)\n",
    "task = DocClassificationTask(\n",
    "    datamodule=datamodule,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer = Trainer(max_epochs=5, fast_dev_run=True)\n",
    "trainer.fit(task, datamodule=datamodule)\n",
    "\n",
    "# test model\n",
    "trainer.test(task, datamodule=datamodule)\n",
    "\n",
    "# export task(transform + model) to TorchScript\n",
    "export_path = \"/tmp/doc_classification_task.pt1\"\n",
    "task.to_torchscript(export_path)\n",
    "\n",
    "# deploy task to server and inference\n",
    "with open(export_path, \"rb\") as f:\n",
    "    ts_module = torch.load(f)\n",
    "    print(ts_module(text_batch=[\"hello world\", \"attention is all your need!\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=DocClassificationTask\n",
      "  (text_transform): RecursiveScriptModule(original_name=WhitespaceTokenizer)\n",
      "  (model): RecursiveScriptModule(\n",
      "    original_name=RobertaModel\n",
      "    (encoder): RecursiveScriptModule(\n",
      "      original_name=RobertaEncoder\n",
      "      (transformer): RecursiveScriptModule(\n",
      "        original_name=Transformer\n",
      "        (token_embedding): RecursiveScriptModule(original_name=Embedding)\n",
      "        (layers): RecursiveScriptModule(\n",
      "          original_name=ModuleList\n",
      "          (0): RecursiveScriptModule(\n",
      "            original_name=TransformerLayer\n",
      "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
      "            (attention): RecursiveScriptModule(\n",
      "              original_name=MultiheadSelfAttention\n",
      "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
      "              (input_projection): RecursiveScriptModule(original_name=Linear)\n",
      "              (output_projection): RecursiveScriptModule(original_name=Linear)\n",
      "            )\n",
      "            (residual_mlp): RecursiveScriptModule(\n",
      "              original_name=ResidualMLP\n",
      "              (mlp): RecursiveScriptModule(\n",
      "                original_name=Sequential\n",
      "                (0): RecursiveScriptModule(original_name=Linear)\n",
      "                (1): RecursiveScriptModule(original_name=GeLU)\n",
      "                (2): RecursiveScriptModule(original_name=Dropout)\n",
      "                (3): RecursiveScriptModule(original_name=Linear)\n",
      "                (4): RecursiveScriptModule(original_name=Dropout)\n",
      "              )\n",
      "            )\n",
      "            (attention_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
      "            (final_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
      "          )\n",
      "        )\n",
      "        (positional_embedding): RecursiveScriptModule(\n",
      "          original_name=PositionalEmbedding\n",
      "          (embedding): RecursiveScriptModule(original_name=Embedding)\n",
      "        )\n",
      "        (embedding_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
      "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
      "      )\n",
      "      (output_dropout): RecursiveScriptModule(original_name=Dropout)\n",
      "    )\n",
      "    (decoder): RecursiveScriptModule(\n",
      "      original_name=MlpDecoder\n",
      "      (mlp): RecursiveScriptModule(\n",
      "        original_name=Sequential\n",
      "        (0): RecursiveScriptModule(original_name=Linear)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss): RecursiveScriptModule(original_name=CrossEntropyLoss)\n",
      "  (valid_acc): RecursiveScriptModule(original_name=Accuracy)\n",
      "  (test_acc): RecursiveScriptModule(original_name=Accuracy)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(ts_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}