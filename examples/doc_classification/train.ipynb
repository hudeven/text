{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!git clone https://github.com/hudeven/text\n",
    "!git clone https://github.com/facebookresearch/pytext\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade --force-reinstall ./text/stl_text/dataframes/datasets;\n",
    "!pip install --upgrade --force-reinstall ./text;\n",
    "\n",
    "!pip install --upgrade --force-reinstall ./pytext;\n",
    "!pip install --upgrade --force-reinstall tensorboard;\n",
    "\n",
    "!pip install --upgrade --force-reinstall --pre torch torchtext -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html;\n",
    "!pip install --upgrade --force-reinstall datasets;\n",
    "\n",
    "!pip install pytorch-lightning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from stl_text.ops.utils.arrow import convert_csv_to_arrow\n",
    "from stl_text.datamodule import DocClassificationDataModule\n",
    "from task import DocClassificationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "converted to arrow and saved to ./glue_sst2_tiny/train\n",
      "converted to arrow and saved to ./glue_sst2_tiny/valid\n",
      "converted to arrow and saved to ./glue_sst2_tiny/test\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-f1e83dde37d3c060.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-e464112f4fa64676.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/train/cache-3301217692ea7b7c.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-d7e81757a0546a02.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-daf7dc6f6a37bdc1.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/valid/cache-a1235ce082fa5b2a.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-4a8ddec11e8e0938.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-a6e5e3e4a7b8c81f.arrow\n",
      "Loading cached processed dataset at ./glue_sst2_tiny/test/cache-c33ac2d9284c0aa3.arrow\n"
     ]
    }
   ],
   "source": [
    "# convert csv to arrow format (only required for the first time)\n",
    "data_path = \"./glue_sst2_tiny\"\n",
    "for split in (\"train.tsv\", \"valid.tsv\", \"test.tsv\"):\n",
    "    split_path = os.path.join(data_path, split)\n",
    "    convert_csv_to_arrow(split_path)\n",
    "\n",
    "# setup datamodule\n",
    "datamodule = DocClassificationDataModule(data_path=data_path, batch_size=8, drop_last=True)\n",
    "datamodule.setup(\"fit\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: \n",
      "{'label_id': tensor([0, 0, 1, 1, 1, 1, 1, 1]), 'seq_len': tensor([19, 19, 20, 20, 20, 20, 21, 23]), 'token_ids': tensor([[128,  28,  52, 129, 100,   2, 130,  77,  48, 131, 132, 133,  14, 134,\n",
      "         135,  28, 136, 137, 128,   0,   0,   0,   0],\n",
      "        [ 80, 210, 211, 212,  30, 213,   2, 214, 176, 215,  39,  77, 216,  30,\n",
      "         217, 218,  77, 175,   8,   0,   0,   0,   0],\n",
      "        [ 12,  13,  14,  15,  16,  17,  18,  19,  14,  20,   2,  21,  22,  23,\n",
      "           2,  24,  25,  26,  27,   8,   0,   0,   0],\n",
      "        [ 28,  29,  30,  31,  30,  32,  30,  33,   4,  34,  35,  36,  37,  38,\n",
      "          28,  39,   1,  40,  41,   8,   0,   0,   0],\n",
      "        [ 68,  69,  70,  71,  14,  72,  73,  32,  14,  74,  28,  52,   1,  75,\n",
      "          76,  77,  78,   4,  79,   8,   0,   0,   0],\n",
      "        [  2, 168,  30, 169, 170, 100, 171,  16, 172, 173,  32,  30, 174,  30,\n",
      "         175,  30,   4, 176, 177,   8,   0,   0,   0],\n",
      "        [ 45,  46,  47,  48,   4,   2,  49,  50,  51,  30,  28,  52,  18,   2,\n",
      "          53,  54,  55,  56,  57,  58,   8,   0,   0],\n",
      "        [138, 139, 140, 131, 141,   4, 142, 137,  30, 143, 144, 145,  30, 146,\n",
      "         147,   0,   1,  95, 148, 149,  14, 150,   8]])}\n",
      "batch 1: \n",
      "{'label_id': tensor([0, 0, 1, 0, 0, 0, 1, 1]), 'seq_len': tensor([ 4,  5,  9,  9, 10, 10, 16, 18]), 'token_ids': tensor([[  9,  10,   4,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0],\n",
      "        [  2,  59,  60,  52,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0],\n",
      "        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0],\n",
      "        [  0,   1,  42,  43,  44,  30,  44,  42,   8,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0],\n",
      "        [ 61,  62,  63,  64,   1,  65,  47,  66,  67,   8,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0],\n",
      "        [128,  28, 127,  18, 206,   2, 207, 208, 209,   8,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0],\n",
      "        [ 28, 105, 106,  77,  28, 107, 108,  28,  52, 109,   4, 108,  28, 110,\n",
      "         111,   8,   0,   0],\n",
      "        [ 28, 178,  35, 179,   4, 153, 180,   2, 181,  47, 182, 183,   1, 184,\n",
      "         185, 186, 187,   8]])}\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(datamodule.train_dataloader()):\n",
    "    print(f\"batch {i}: \\n{batch}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es)\n",
      "/Users/stevenliu/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | loss      | CrossEntropyLoss | 0     \n",
      "1 | valid_acc | Accuracy         | 0     \n",
      "2 | test_acc  | Accuracy         | 0     \n",
      "3 | model     | RobertaModel     | 13.5 M\n",
      "-----------------------------------------------\n",
      "13.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.5 M    Total params\n",
      "/Users/stevenliu/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), maxâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe5ae13236734879bddc0448e4e26339"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\nModule 'XlmrDocClassificationTask' has no attribute 'datamodule' :\n  File \"/Users/stevenliu/workspace/hack_week/text/examples/xlmr_doc_classification/task.py\", line 40\n    def forward(self, text_batch: List[str]) -> Tensor:\n        token_ids: List[Tensor] = [torch.tensor(self.datamodule.text_transform(text), dtype=torch.long) for text in text_batch]\n                                                ~~~~~~~~~~~~~~~ <--- HERE\n        model_inputs: Tensor = pad_sequence(token_ids, batch_first=True)\n        return self.model(model_inputs)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-352143b886e6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;31m# export to TorchScript\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mexport_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/tmp/doc_task.pt1\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mtask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_torchscript\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/tmp/doc_task.pt1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexport_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mts_module\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py\u001B[0m in \u001B[0;36mto_torchscript\u001B[0;34m(self, file_path, method, example_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1629\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1630\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmethod\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'script'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1631\u001B[0;31m                 \u001B[0mtorchscript_module\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscript\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1632\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mmethod\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'trace'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1633\u001B[0m                 \u001B[0;31m# if no example inputs are provided, try to see if model has example_input_array set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/torch/jit/_script.py\u001B[0m in \u001B[0;36mscript\u001B[0;34m(obj, optimize, _frames_up, _rcb)\u001B[0m\n\u001B[1;32m    896\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    897\u001B[0m         return torch.jit._recursive.create_script_module(\n\u001B[0;32m--> 898\u001B[0;31m             \u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recursive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfer_methods_to_compile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    899\u001B[0m         )\n\u001B[1;32m    900\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_script_module\u001B[0;34m(nn_module, stubs_fn, share_types)\u001B[0m\n\u001B[1;32m    368\u001B[0m     \u001B[0mcheck_module_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    369\u001B[0m     \u001B[0mconcrete_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_module_concrete_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshare_types\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 370\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcreate_script_module_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    371\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcreate_script_module_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    428\u001B[0m     \u001B[0;31m# Compile methods if necessary\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    429\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mconcrete_type\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mconcrete_type_store\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethods_compiled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 430\u001B[0;31m         \u001B[0mcreate_methods_and_properties_from_stubs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_stubs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperty_stubs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    431\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_emit_module_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcpp_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m         \u001B[0mconcrete_type_store\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethods_compiled\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconcrete_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/hack_week/lib/python3.7/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_methods_and_properties_from_stubs\u001B[0;34m(concrete_type, method_stubs, property_stubs)\u001B[0m\n\u001B[1;32m    320\u001B[0m     \u001B[0mproperty_rcbs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresolution_callback\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mproperty_stubs\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 322\u001B[0;31m     \u001B[0mconcrete_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_methods_and_properties\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproperty_defs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperty_rcbs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_defs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_rcbs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \nModule 'XlmrDocClassificationTask' has no attribute 'datamodule' :\n  File \"/Users/stevenliu/workspace/hack_week/text/examples/xlmr_doc_classification/task.py\", line 40\n    def forward(self, text_batch: List[str]) -> Tensor:\n        token_ids: List[Tensor] = [torch.tensor(self.datamodule.text_transform(text), dtype=torch.long) for text in text_batch]\n                                                ~~~~~~~~~~~~~~~ <--- HERE\n        model_inputs: Tensor = pad_sequence(token_ids, batch_first=True)\n        return self.model(model_inputs)\n"
     ]
    }
   ],
   "source": [
    "# construct task\n",
    "task = XlmrDocClassificationTask(datamodule=datamodule, num_class=2,\n",
    "                                 lr=0.01)\n",
    "\n",
    "# train model\n",
    "trainer = Trainer(max_epochs=5, fast_dev_run=True)\n",
    "trainer.fit(task, datamodule=datamodule)\n",
    "\n",
    "# export to TorchScript\n",
    "export_path = \"/tmp/doc_task.pt1\"\n",
    "task.to_torchscript(\"/tmp/doc_task.pt1\")\n",
    "with open(export_path, \"rb\") as f:\n",
    "    ts_module = torch.load(f)\n",
    "    print(ts_module(text_batch=[\"hello world\", \"attend is all your need!\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts_module\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}